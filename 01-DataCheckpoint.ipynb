{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Instructions: DELETE this cell before you submit via a `git push` to your repo before deadline. This cell is for your reference only and is not needed in your report. \n",
    "\n",
    "Scoring: Out of 10 points\n",
    "\n",
    "- Each Developing  => -2 pts\n",
    "- Each Unsatisfactory/Missing => -4 pts\n",
    "  - until the score is \n",
    "\n",
    "If students address the detailed feedback in a future checkpoint they will earn these points back\n",
    "\n",
    "\n",
    "|                  | Unsatisfactory                                                                                                                                                                                                    | Developing                                                                                                                                                                                              | Proficient                                     | Excellent                                                                                                                              |\n",
    "|------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Data relevance   | Did not have data relevant to their question. Or the datasets don't work together because there is no way to line them up against each other. If there are multiple datasets, most of them have this trouble | Data was only tangentially relevant to the question or a bad proxy for the question. If there are multiple datasets, some of them may be irrelevant or can't be easily combined.                       | All data sources are relevant to the question. | Multiple data sources for each aspect of the project. It's clear how the data supports the needs of the project.                         |\n",
    "| Data description | Dataset or its cleaning procedures are not described. If there are multiple datasets, most have this trouble                                                                                              | Data was not fully described. If there are multiple datasets, some of them are not fully described                                                                                                      | Data was fully described                       | The details of the data descriptions and perhaps some very basic EDA also make it clear how the data supports the needs of the project. |\n",
    "| Data wrangling   | Did not obtain data. They did not clean/tidy the data they obtained.  If there are multiple datasets, most have this trouble                                                                                 | Data was partially cleaned or tidied. Perhaps you struggled to verify that the data was clean because they did not present it well. If there are multiple datasets, some have this trouble | The data is cleaned and tidied.                | The data is spotless and they used tools to visualize the data cleanliness and you were convinced at first glance                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "- Yuchen Hou: Background research\n",
    "- Minkyung Gwak: Background research\n",
    "- Nicolas Leedy: Background research\n",
    "- Mowen Tan: Background research\n",
    "- Iris Liu: Background research"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do admission rates and yield rates differ for international, out-of-state, and in-state undergraduate applicants to UC San Diego, and have the gaps between these groups widened or narrowed between 2020 and 2025?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Admission decisions at selective public universities shape not only the composition of the student body but also reflect institutional priorities and structural constraints. Within the University of California (UC) system, campuses receive applications from multiple residency categories, including California residents (in-state), domestic non-residents (out-of-state), and international applicants. These groups differ in tuition structure, financial contribution, and application volume, making comparisons of admission and enrollment outcomes particularly important. UC San Diego (UCSD), as a highly selective public research institution, provides a useful context for examining how admission rates and yield rates vary across residency groups. Public UC admissions datasets provide counts of applicants, admitted students, and enrolled students by residency status, enabling direct analysis of both admission probabilities and post-admission enrollment behavior.<a href=\" \">1</a >\n",
    "\n",
    "Prior research and institutional analyses have emphasized that understanding university access requires examining rates rather than only aggregate enrollment numbers. Summaries provided by the University of California Office of the President highlight how Proposition 209 reshaped admissions practices and underscore the importance of evaluating application, admission, and enrollment patterns separately.<a href=\"#ref3\">3</a > These analyses suggest that raw enrollment totals alone may obscure underlying differences in admissions dynamics. Empirical work examining UC admissions policies similarly demonstrates that changes in student composition may arise from shifts in applicant behavior, selection processes, and institutional factors, motivating closer examination of admission probabilities across groups.<a href=\"#ref3\">3</a >\n",
    "\n",
    "Contemporary reporting further illustrates the relevance of residency-based comparisons. Recent coverage by the Los Angeles Times documents record numbers of California applicants alongside continued international enrollment growth, highlighting how applicant pools and admissions outcomes may evolve over time.<a href=\"#ref2\">2</a > Policy commentary also points to structural barriers affecting California students, including disparities in academic preparation and access to advising resources, which may influence both application behavior and admissions outcomes.<a href=\"#ref4\">4</a > Together, these discussions motivate systematic quantitative investigation of how admission rates and yield rates differ across residency categories.\n",
    "\n",
    "Building on prior work, this project investigates how admission rates and yield rates differ for international, out-of-state, and in-state undergraduate applicants to UC San Diego between 2020 and 2025, and whether gaps between these groups have widened or narrowed over time.\n",
    "\n",
    "\n",
    "References\n",
    "\n",
    "<a name=\"ref1\">1</a > University of California Admissions. UC San Diego First-Year Admit Data.\n",
    "https://admission.universityofcalifornia.edu/campuses-majors/san-diego/first-year-admit-data.html\n",
    "\n",
    "<a name=\"ref2\">2</a > Los Angeles Times. UC Admissions and Residency Trends.\n",
    "https://www.latimes.com/california/story/2025-07-28/uc-fall-2025-admissions-record-number-from-california-international-students-racial-diversity\n",
    "\n",
    "<a name=\"ref3\">3</a > Bleemer, Z. The Impact of Proposition 209 and Access-Oriented UC Admissions Policies.\n",
    "https://www.ucop.edu/institutional-research-academic-planning/_files/uc-affirmative-action.pdf\n",
    "\n",
    "<a name=\"ref4\">4</a > CalMatters. Barriers Facing California Students Seeking UC Admission.\n",
    "https://calmatters.org/commentary/2026/01/college-barriers-uc-california-students/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesize that there are distinct patterns across first generation, undocumented, and international students admitted to UC San Diego(2020-2025) across ethnicity, gender, and intended major. Specifically, due to cultural and economic factors, we believe that first generation and International will share considerable concentration in STEM-based majors, and that first generation will have a disproportionate percentage of underrepresented ethnicities while international students will show a different distribution of ethnicities and genders. \n",
    "\n",
    "We expect that the focus on STEM majors is influenced by economic stability. International students have increased costs due to travel and education expenses which may incentivize financial predictability with potential of high return when picking a major. Similarly, first generation students may prefer STEM as there is a higher financial floor and increased opportunities following graduation. On the other hand, first generation students may be disproportionately underrepresented ethnicities due to historical disparities in K-12 education, college counseling, and opportunity. International students have differing constraints which come in the form of restrictions of certain countries to send students to the US as well as socioeconomic differences across the world.  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data overview\n",
    "\n",
    "Instructions: REPLACE the contents of this cell with descriptions of your actual datasets.\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "  - Description of the variables most relevant to this project\n",
    "  - Descriptions of any shortcomings this dataset has with repsect to the project\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - same as above\n",
    "- etc\n",
    "\n",
    "Each dataset deserves either a set of bullet points as above or a few sentences if you prefer that method.\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code every time when you're actively developing modules in .py files.  It's not needed if you aren't making modules\n",
    "#\n",
    "## this code is necessary for making sure that any modules we load are updated here \n",
    "## when their source code .py files are modified\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code -- this only needs to be run once after cloning the repo!\n",
    "# this code downloads the data from its source to the `data/00-raw/` directory\n",
    "# if the data hasn't updated you don't need to do this again!\n",
    "\n",
    "# if you don't already have these packages (you should!) uncomment this line\n",
    "# %pip install requests tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('./modules') # this tells python where to look for modules to import\n",
    "\n",
    "import get_data # this is where we get the function we need to download data\n",
    "\n",
    "# replace the urls and filenames in this list with your actual datafiles\n",
    "# yes you can use Google drive share links or whatever\n",
    "# format is a list of dictionaries; \n",
    "# each dict has keys of \n",
    "#   'url' where the resource is located\n",
    "#   'filename' for the local filename where it will be stored \n",
    "datafiles = [\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/airline-safety/airline-safety.csv', 'filename':'airline-safety.csv'},\n",
    "    { 'url': 'https://raw.githubusercontent.com/fivethirtyeight/data/refs/heads/master/bad-drivers/bad-drivers.csv', 'filename':'bad-drivers.csv'}\n",
    "]\n",
    "\n",
    "get_data.get_raw(datafiles,destination_directory='data/00-raw/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #1 \n",
    "\n",
    "Instructions: \n",
    "1. Change the header from Dataset #1 to something more descriptive of the dataset\n",
    "2. Write a few paragraphs about this dataset. Make sure to cover\n",
    "   1. Describe the important metrics, what units they are in, and giv some sense of what they mean.  For example \"Fasting blood glucose in units of mg glucose per deciliter of blood.  Normal values for healthy individuals range from 70 to 100 mg/dL.  Values 100-125 are prediabetic and values >125mg/dL indicate diabetes. Values <70 indicate hypoglycemia. Fasting idicates the patient hasn't eaten in the last 8 hours.  If blood glucose is >250 or <50 at any time (regardless of the time of last meal) the patient's life may be in immediate danger\"\n",
    "   2. If there are any major concerns with the dataset, describe them. For example \"Dataset is composed of people who are serious enough about eating healthy that they voluntarily downloaded an app dedicated to tracking their eating patterns. This sample is likely biased because of that self-selection. These people own smartphones and may be healthier and may have more disposable income than the average person.  Those who voluntarily log conscientiously and for long amounts of time are also likely even more interested in health than those who download the app and only log a bit before getting tired of it\"\n",
    "3. Use the cell below to \n",
    "    1. load the dataset \n",
    "    2. make the dataset tidy or demonstrate that it was already tidy\n",
    "    3. demonstrate the size of the dataset\n",
    "    4. find out how much data is missing, where its missing, and if its missing at random or seems to have any systematic relationships in its missingness\n",
    "    5. find and flag any outliers or suspicious entries\n",
    "    6. clean the data or demonstrate that it was already clean.  You may choose how to deal with missingness (dropna of fillna... how='any' or 'all') and you should justify your choice in some way\n",
    "    7. You will load raw data from `data/00-raw/`, you will (optionally) write intermediate stages of your work to `data/01-interim` and you will write the final fully wrangled version of your data to `data/02-processed`\n",
    "4. Optionally you can also show some summary statistics for variables that you think are important to the project\n",
    "5. Feel free to add more cells here if that's helpful for you\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset #2 \n",
    "\n",
    "See instructions above for Dataset #1.  Feel free to keep adding as many more datasets as you need.  Put each new dataset in its own section just like these. \n",
    "\n",
    "Lastly if you do have multiple datasets, add another section where you demonstrate how you will join, align, cross-reference or whatever to combine data from the different datasets\n",
    "\n",
    "Please note that you can always keep adding more datasets in the future if these datasets you turn in for the checkpoint aren't sufficient.  The goal here is demonstrate that you can obtain and wrangle data.  You are not tied down to only use what you turn in right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE TO LOAD/CLEAN/TIDY/WRANGLE THE DATA GOES HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> Since we're using public, aggregated admissions statistics and data from UC San Diego instead of individual records, informed consent isn't applicable in this situation. However, we'll still make sure to be sensitive in our analysis since it can influence narratives and assumptions about specific applicant groups. We'll make sure to make responsible reports in order to avoid targeting and stigmatization.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> Biases could be introduced through reporting and definition differences throughout the years. For example, how the dataset defines words like \"international\", \"out of state\", and \"in state\" could change with different reporting cycles, and the university's formating could change as well. To limit biases, we'll rely on official definitions of that year and check for consistency in demnominators, and take into account any discontinuities in reporting.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> We'll only collect fields needed to analyze our research question, like the year, international/out of state/in state, and admission and yield rates. We won't use individual records, names, IDs, and application attributes. In the case that we do add subgroup breakdowns (ex. by major or by UCSD colleges), we'll use small cell supression and avoid creating tables where a group could be indirectly identified. \n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> Since international/out of state/in state groups could easily be misused to argue that certain groups are more or less deserving of their acceptance/rejectance we'll present results as institutional outcomes rather than as judgements about individuals. We'll avoid using deficit language, attributing motivations, and explicitly state that many differences could reflect many factors (like application volume, financial aid, visa constraints, housing capacity) that aren't easily observable in aggregate reporting. \n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> Though our source is public, our intersectional tables will be more sensitive than the original public data. We'll store files in a private page, avoid sharing raw derived tabs, and only sharing aggregated output when publishing. \n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> Because we don't have individual level records and only publicly published aggregated, we can't remove an individual's data from the CDS.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "> We'll only keep anything needed for reproducibility, like links and citations and code to re download the CDS. However, we'll delete intermediate derived cross tabs, especially ones containing smaller cells. \n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> Our interpretation of demographic differences can be shaped by our own assumptions. We'll make sure to ground conclusions in CDS documentation, check interpretations with peers and TAs, and avoid making normative judgements about international/in state/out of state groups. We'll also try to incorporate institutional context on what reported categories mean.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> The CDS isn't designed for causal inference and may not include confounders like applicant pool composition, policy changes, and reporting changes. We'll try to avoid causal language, check for discontinuities that suggest definitional changes, and refrain from making claims that can't be supported by aggregate reporting.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> We'll use consistent denominators and clearly label whether values are counts or percentages. We'll make sure to include totals and disclose when things are labeled as \"unknown/not reported\", avoid misleading axis scales, and avoid emphasizing categories that exaggerate differences.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> Our analysis only uses aggregated counts by residency group and year, and doesn't use individual records or direct identifiers. We'll try not to infer or reconstruct individual outcomes. In the case we do introduce additional subgroup analyses, we'll suppress small cells and avoid publishing cross tabs that could lead to indirect identification\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> We'll keep our code and maintain a clear data provenance record like which CDS file and year we used, which tables, and which transformations were applied. Any recoding and suppression will be documented so results can be reproduced and corrected in case issues are found.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> Though we're not building a predictive model, we'll still make sure to be mindful of analytical choices like grouping majors and creating categories, which could function like proxies that could unfairly shift narratives. We'll make sure to justify each grouping choice.\n",
    "\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "> We'll present both counts and proportions and show multiple perspectives like the composition of admit versus admit rates within each subgroup. This makes sure it isn't easy for a single metric to create misleading conclusions. \n",
    "\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> We'll include a limitations section to emphasize aggregated reporting, definitional changes across years, missing data, small cell suppression, and the fact that our results are descriptive and not meant for individual level conclusions or causal claims. \n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "> We'll regularly review the published analysis for misinterpretation risks, especially if the university changes reporting formats and definitioins. If we find a figure is misused or misleading due to changes in definitions, we'll update or retract it. \n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "> If we find that our output is misleading, creates stigmas, or creates privacy risks, we'll correct it and either add clarifications or remove it. We'll document changes to maintain transparency.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "> Since this is a published report and not a live system/model, rollback for us would mean removing or revising figures and tables and documenting changes in a log. \n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "> A key use could be misusing demographic breakdowns to stereotype and create exclusionary arguments. We'll mitigate this by avoiding normative claims, providing contextual limitations, and adding a statement to only use it for appropriate use. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Individual members are expected to complete their assigned parts of a given task on time.\n",
    "* Members are expected to communicate to each other through text, Zoom, and in-person meetings every week.\n",
    "* Members are expected to address conflicts calmly and focus on solutions beneficial to the team.\n",
    "* Members are expected to support each other, share resources, and ask for help when needed to ensure the team succeeds. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---| \n",
    "| 2/1  | 4:00 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/3  |  8:00 PM |  Read 3–5 peer-reviewed articles related to International Student Admissions; summarize key findings in shared doc (at least 5 bullet points per person). | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/4  | 7:00 PM | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14 | 8:00 PM | Being clear and think about what's the problem of the project proposal. Plan a workflow to refine everyones' own distibuted part. | Discuss how to refine our project proposal as a whole. Help each other (provide advice) to figure out some existing problems|\n",
    "| 2/18  | 8:30 PM  | Work session：Data Integration: Merge multiple datasets; Initial Cleaning:Quantify missingness (% per column); decide between drop vs. imputation (mean/median/mode); document decision in notebook markdown. | Wrangling Review: Verify data integrity after merging; EDA Deep Dive: Analyze distributions of key variables & identify outliers; Refine Analysis Plan: Select specific statistical tests/models based on EDA trends.   |\n",
    "| 2/22 | 8:00 PM | Advanced EDA: Generate correlation matrix & scatterplot matrices; Initial Hypothesis Testing.| Feature Selection: Discuss which variables to keep/drop based on correlation; Address Data Bias: Identify any systematic bias in the dataset (Ethics).|\n",
    "| 2/28 | 8:00 PM | Feature Engineering: One-hot encoding for categorical data; Scaling/Normalization of numerical data | Define Analysis Pipeline: Finalize the choice of ML models (e.g., Regression vs. Classification); Assign members to code specific models. |\n",
    "| 3/4  | 8:00 PM | Execute Baseline Models; Generate performance metrics (e.g., Accuracy, MSE, R-squared). | Model Evaluation: Compare performance across different models; Identify potential underfitting or overfitting; Complete project check-in. |\n",
    "| 3/11  | 8:00 PM (Tentative) | Hyperparameter Tuning: Refine models for better performance; Finalize Visualizations (Final polished plots). | Result Interpretation: Explain the \"Why\" behind the results; Finalize Ethics & Privacy discussion based on final results; Relate findings back to original hypothesis; evaluate whether results support or reject it (statistical significance threshold α=0.05). Review project limitations. |\n",
    "| 3/12  | 8:00 PM (Tentative) | Draft Results, Conclusion, and Discussion sections; Clean up Jupyter Notebook code and comments. | Full Project Review: Peer-edit the narrative for clarity and flow; Ensure reproducibility (Run the notebook from top to bottom). |\n",
    "| 3/18  | Before 11:59 PM  | Final proofreading; Ensure all citations and references are formatted correctly. | Final Submission: Turn in Final Project & complete Group Project Surveys. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version Control & Workflow\n",
    "\n",
    "We will use GitHub for version control. Each team member will work on separate feature branches and submit pull requests before merging into the main branch. All major analytical decisions (e.g., data cleaning strategies, model selection, evaluation metrics) will be documented in markdown cells within the notebook. We will ensure full reproducibility by running the notebook from top to bottom before submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
