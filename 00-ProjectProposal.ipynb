{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rubric\n",
    "\n",
    "**Scoring:** Out of $10$ points\n",
    "\n",
    "- Each Developing => $-1$ pts\n",
    "- Each Unsatisfactory/Missing => $-2$ pts\n",
    "\t- until the score is 0\n",
    "\n",
    "If students address the detailed feedback in a future checkpoint, they will **earn these points back**.\n",
    "\n",
    "\n",
    "|                   | Unsatisfactory                                                                                                                                                                                                                                                                                    | Developing                                                                                                                                                                                                                                                                                                                                   | Proficient                                                                                                                                                                                                                                                    | Excellent                                                                                                                                                                                                                                                                                                                      |\n",
    "|-------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| Research question | The research issue remains unclear. The research purpose, questions, hypotheses, definitions variables, and controls are still largely undefined, or when they are poorly formed, ambiguous, or not logically connected to the description of the problem. Unclear connections to the literature. | The research issue is identified, but the statement is too broad or fails to establish the importance of the problem. The research purpose, questions, hypotheses, definitions or variables, and controls are poorly formed, ambiguous, or not logically connected to the description of the problem. Unclear connections to the literature. | Identifies a relevant research issue. Research questions are succinctly stated, connected to the research issue, and supported by the literature. Variables and controls have been identified and described. Connections are established with the literature. | Presents a significant research problem. Articulates clear, reasonable research questions given the purpose, design, and methods of the project. All variables and controls have been appropriately defined. Proposals are clearly supported by the research and theoretical literature. All elements are mutually supportive. |\n",
    "| Background        | Did not have at least 2 reliable and relevant sources. Or relevant sources were not used in relevant ways                                                                                                                                                                                         | A key component was not connected to the research literature. Selected literature was from unreliable sources. Literary supports were vague or ambiguous.                                                                                                                                                                                    | Key research components were connected to relevant, reliable theoretical and research literature.                                                                                                                                                             | The narrative integrates critical and logical details from the peer-reviewed theoretical and research literature. Each key research component is grounded in the literature. Attention is given to different perspectives, threats to validity, and opinion vs. evidence.                                                      |\n",
    "| Hypothesis        | Lacks most details; vague or interpretable in different ways. Or seems completely unrealistic.                                                                                                                                                                                                    | A key detail to understand the hypothesis or the rationale behind it was not described well enough                                                                                                                                                                                                                                           | The hypothesis is clear. All elements needed to understand the rationale were described in sufficient detail                                                                                                                                                  | The hypothesis and its rationale were described succinctly and with clarity about how they are connected to each other                                                                                                                                                                                                         |\n",
    "| Data              | Did not describe ideal dataset fully AND does not include at least one reference to an external source of data.                                                                                                                                                                         | Either does not describe the ideal dataset fully AND does not include at least one reference to an external source of data that could be used to answer the proposed question.                                                                                                                                                                                                                                                            | Ideal dataset(s) well-described and includes everything needed for answering question(s) posed. Includes at least one reference to a source of data that would be needed to fully answer the question proposed.                                                                                                                                                            | Ideal dataset(s) well-described and includes everything needed for answering question(s) posed. Includes references to all sources of data that would be needed to fully answer the question proposed. The details of the descriptions also make it clear how they support the needs of the project and discuss the differences betweeen the ideal and real datasets.                                                                                                                       |\n",
    "| Ethics            | No effort or just says we have no ethical concerns                                                                                                                                                                                                                                                | Minimal ethical section; probably just talks about data privacy and no unintended consequences discussion. Ethical concerns raised seem irrelevant.                                                                                                                                                                                          | The ethical concerns described are appropriate and sufficiently                                                                                                                                                                                               | Ethical concerns are described clearly and succinctly. This was clearly a thorough and nuanced approach to the issues                                                                                                                                                                                                          |\n",
    "| Team expectations | Lack of expectations                                                                                                                                                                                                                                                                              | The list of expectations feels incomplete and perfunctory                                                                                                                                                                                                                                                                                    | It feels like the list of expectations is complete and seems appropriate                                                                                                                                                                                      | The list clearly was the subject of a thoughtful approach and already indicates a well-working team                                                                                                                                                                                                                            |\n",
    "| Timeline          | Lack of timeline. Or timeline is completely unrealistic                                                                                                                                                                                                                                           | The timeline feels incomplete and perfunctory. The timeline feels either too fast or too slow for the progress you expect a group can make                                                                                                                                                                                                   | It feels like the timeline is complete and appropriate. it can likely be completed as is in the available amount of time                                                                                                                                      | The timeline was clearly the subject of a thoughtful approach and indicates that the team has a detailed plan that seems appropriate and completeable in the allotted time.                                                                                                                                                    |\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Project Proposal\n",
    "\n",
    "## Authors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a modified [CRediT taxonomy of contributions](https://credit.niso.org). For each group member please list how they contributed to this project using these terms:\n",
    "> Analysis, Background research, Conceptualization, Data curation, Experimental investigation, Methodology, Project administration, Software, Visualization, Writing – original draft, Writing – review & editing\n",
    "\n",
    "- Yuchen Hou: Background research\n",
    "- Minkyung Gwak: Background research\n",
    "- Nicolas Leedy: Background research\n",
    "- Mowen Tan: Background research\n",
    "- Iris Liu: Background research"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do admission rates and yield rates differ for international, out-of-state, and in-state undergraduate applicants to UC San Diego, and have the gaps between these groups widened or narrowed between 2020 and 2025?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Admission decisions at selective public universities shape not only the composition of the student body but also reflect institutional priorities and structural constraints. Within the University of California (UC) system, campuses receive applications from multiple residency categories, including California residents (in-state), domestic non-residents (out-of-state), and international applicants. These groups differ in tuition structure, financial contribution, and application volume, making comparisons of admission and enrollment outcomes particularly important. UC San Diego (UCSD), as a highly selective public research institution, provides a useful context for examining how admission rates and yield rates vary across residency groups. Public UC admissions datasets provide counts of applicants, admitted students, and enrolled students by residency status, enabling direct analysis of both admission probabilities and post-admission enrollment behavior.<a href=\" \">1</a >\n",
    "\n",
    "Prior research and institutional analyses have emphasized that understanding university access requires examining rates rather than only aggregate enrollment numbers. Summaries provided by the University of California Office of the President highlight how Proposition 209 reshaped admissions practices and underscore the importance of evaluating application, admission, and enrollment patterns separately.<a href=\"#ref3\">3</a > These analyses suggest that raw enrollment totals alone may obscure underlying differences in admissions dynamics. Empirical work examining UC admissions policies similarly demonstrates that changes in student composition may arise from shifts in applicant behavior, selection processes, and institutional factors, motivating closer examination of admission probabilities across groups.<a href=\"#ref3\">3</a >\n",
    "\n",
    "Contemporary reporting further illustrates the relevance of residency-based comparisons. Recent coverage by the Los Angeles Times documents record numbers of California applicants alongside continued international enrollment growth, highlighting how applicant pools and admissions outcomes may evolve over time.<a href=\"#ref2\">2</a > Policy commentary also points to structural barriers affecting California students, including disparities in academic preparation and access to advising resources, which may influence both application behavior and admissions outcomes.<a href=\"#ref4\">4</a > Together, these discussions motivate systematic quantitative investigation of how admission rates and yield rates differ across residency categories.\n",
    "\n",
    "Building on prior work, this project investigates how admission rates and yield rates differ for international, out-of-state, and in-state undergraduate applicants to UC San Diego between 2020 and 2025, and whether gaps between these groups have widened or narrowed over time.\n",
    "\n",
    "\n",
    "References\n",
    "\n",
    "<a name=\"ref1\">1</a > University of California Admissions. UC San Diego First-Year Admit Data.\n",
    "https://admission.universityofcalifornia.edu/campuses-majors/san-diego/first-year-admit-data.html\n",
    "\n",
    "<a name=\"ref2\">2</a > Los Angeles Times. UC Admissions and Residency Trends.\n",
    "https://www.latimes.com/california/story/2025-07-28/uc-fall-2025-admissions-record-number-from-california-international-students-racial-diversity\n",
    "\n",
    "<a name=\"ref3\">3</a > Bleemer, Z. The Impact of Proposition 209 and Access-Oriented UC Admissions Policies.\n",
    "https://www.ucop.edu/institutional-research-academic-planning/_files/uc-affirmative-action.pdf\n",
    "\n",
    "<a name=\"ref4\">4</a > CalMatters. Barriers Facing California Students Seeking UC Admission.\n",
    "https://calmatters.org/commentary/2026/01/college-barriers-uc-california-students/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We hypothesize that acceptance and yield rates will differ from international, out-of-state, and in-state student populations at UCSD from 2020 to 2025. Specifically, due to costs and travel restrictions, we believe international students will have a lower percentage yield than that of in-state and out-of-state students over the 5 year span. We also expect that acceptance rates will differ across these groups over these years in accordance with differences in finances and application priorities.\n",
    "\n",
    "\n",
    "We expect that International students and out-of-state students will have lower yield percentages because of the higher tuition costs of going to UCSD relative to in-state counterparts. Additionally international students have student visas and travel constraints that may force accepted students to not be able to attend. This uncertainty in the admissions process will develop lower yield results over the 5 year span between each residency group. Additionally, We expect that admissions rates across groups will differ significantly due to application priorities and admissions pools. As a public university UC San Diego must prioritize in-state admissions, but when looking at application priorities, International and out-of-state students may have advantageous academic profiles due to the diversity of their programs and an ability to pay the higher tuition costs further funding the school. \n",
    " \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "The ideal data set for this project would have the following variables (year, residency group, applied, admitted, and enrolled) This would allow to get all 9 years of data, each year would contain (in-state, out-of-state, and International) and then each of those three will have (applied, admitted, enrolled)\n",
    "The data would come from all 9 years which should be around 81 data points \n",
    "This information can be found on the UCSD IR website which contains the UCSD common data set. \n",
    "The data would be organized as follows:\n",
    "\n",
    "index,\tyear,\tresidency status,\tapplied,\taccepted,\tenrolled\n",
    "\n",
    "0,\t2020,\tin-state,\tx,\ty,\tz\n",
    "\n",
    "1,\t2020,\tout-of-state,\tx,\ty,\tz,\n",
    "\n",
    "3.\n",
    "The url to find this data would be https://www.universityofcalifornia.edu/about-us/information-center/admissions-residency-and-ethnicity \n",
    "This dataset contains a bunch of data however the important data that we would like to extract is the first time first year student applicants section which has a datafram that includes (in-state, out-of-state, and international students) and the (applied, admitted, and enrolled statistics as shown below \n",
    "\n",
    "Just looking at one year of this aggregated data would not be enough so we have gathered the info over 9 years which should include a total of 81 data points. These data points are representative of individuals however it is impossible to find each individual student's info. By working with this aggregated data we would work with percentages based on each year. Using equations like admitted/applied to look at trends regarding admission bias or using enrolled/admitted to look at yield rates.\n",
    "\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ethics \n",
    "\n",
    "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
    "\n",
    "### A. Data Collection\n",
    " - [X] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
    "\n",
    "> Since we're using public, aggregated admissions statistics and data from UC San Diego instead of individual records, informed consent isn't applicable in this situation. However, we'll still make sure to be sensitive in our analysis since it can influence narratives and assumptions about specific applicant groups. We'll make sure to make responsible reports in order to avoid targeting and stigmatization.\n",
    "\n",
    " - [X] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
    "\n",
    "> Biases could be introduced through reporting and definition differences throughout the years. For example, how the dataset defines words like \"international\", \"out of state\", and \"in state\" could change with different reporting cycles, and the university's formating could change as well. To limit biases, we'll rely on official definitions of that year and check for consistency in demnominators, and take into account any discontinuities in reporting.\n",
    "\n",
    " - [X] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
    "\n",
    "> We'll only collect fields needed to analyze our research question, like the year, international/out of state/in state, and admission and yield rates. We won't use individual records, names, IDs, and application attributes. In the case that we do add subgroup breakdowns (ex. by major or by UCSD colleges), we'll use small cell supression and avoid creating tables where a group could be indirectly identified. \n",
    "\n",
    " - [X] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
    "\n",
    "> Since international/out of state/in state groups could easily be misused to argue that certain groups are more or less deserving of their acceptance/rejectance we'll present results as institutional outcomes rather than as judgements about individuals. We'll avoid using deficit language, attributing motivations, and explicitly state that many differences could reflect many factors (like application volume, financial aid, visa constraints, housing capacity) that aren't easily observable in aggregate reporting. \n",
    "\n",
    "### B. Data Storage\n",
    " - [X] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
    "\n",
    "> Though our source is public, our intersectional tables will be more sensitive than the original public data. We'll store files in a private page, avoid sharing raw derived tabs, and only sharing aggregated output when publishing. \n",
    "\n",
    " - [X] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
    "\n",
    "> Because we don't have individual level records and only publicly published aggregated, we can't remove an individual's data from the CDS.\n",
    "\n",
    " - [X] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
    "\n",
    "> We'll only keep anything needed for reproducibility, like links and citations and code to re download the CDS. However, we'll delete intermediate derived cross tabs, especially ones containing smaller cells. \n",
    "\n",
    "### C. Analysis\n",
    " - [X] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
    "\n",
    "> Our interpretation of demographic differences can be shaped by our own assumptions. We'll make sure to ground conclusions in CDS documentation, check interpretations with peers and TAs, and avoid making normative judgements about international/in state/out of state groups. We'll also try to incorporate institutional context on what reported categories mean.\n",
    "\n",
    " - [X] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
    "\n",
    "> The CDS isn't designed for causal inference and may not include confounders like applicant pool composition, policy changes, and reporting changes. We'll try to avoid causal language, check for discontinuities that suggest definitional changes, and refrain from making claims that can't be supported by aggregate reporting.\n",
    "\n",
    " - [X] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
    "\n",
    "> We'll use consistent denominators and clearly label whether values are counts or percentages. We'll make sure to include totals and disclose when things are labeled as \"unknown/not reported\", avoid misleading axis scales, and avoid emphasizing categories that exaggerate differences.\n",
    "\n",
    " - [X] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
    "\n",
    "> Our analysis only uses aggregated counts by residency group and year, and doesn't use individual records or direct identifiers. We'll try not to infer or reconstruct individual outcomes. In the case we do introduce additional subgroup analyses, we'll suppress small cells and avoid publishing cross tabs that could lead to indirect identification\n",
    "\n",
    " - [X] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
    "\n",
    "> We'll keep our code and maintain a clear data provenance record like which CDS file and year we used, which tables, and which transformations were applied. Any recoding and suppression will be documented so results can be reproduced and corrected in case issues are found.\n",
    "\n",
    "### D. Modeling\n",
    " - [X] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
    "\n",
    "> Though we're not building a predictive model, we'll still make sure to be mindful of analytical choices like grouping majors and creating categories, which could function like proxies that could unfairly shift narratives. We'll make sure to justify each grouping choice.\n",
    "\n",
    " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
    "\n",
    " - [X] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
    "\n",
    "> We'll present both counts and proportions and show multiple perspectives like the composition of admit versus admit rates within each subgroup. This makes sure it isn't easy for a single metric to create misleading conclusions. \n",
    "\n",
    " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
    " - [X] **D.5 Communicate limitations**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
    "\n",
    "> We'll include a limitations section to emphasize aggregated reporting, definitional changes across years, missing data, small cell suppression, and the fact that our results are descriptive and not meant for individual level conclusions or causal claims. \n",
    "\n",
    "### E. Deployment\n",
    " - [X] **E.1 Monitoring and evaluation**: Do we have a clear plan to monitor the model and its impacts after it is deployed (e.g., performance monitoring, regular audit of sample predictions, human review of high-stakes decisions, reviewing downstream impacts of errors or low-confidence decisions, testing for concept drift)?\n",
    "\n",
    "> We'll regularly review the published analysis for misinterpretation risks, especially if the university changes reporting formats and definitioins. If we find a figure is misused or misleading due to changes in definitions, we'll update or retract it. \n",
    "\n",
    " - [X] **E.2 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
    "\n",
    "> If we find that our output is misleading, creates stigmas, or creates privacy risks, we'll correct it and either add clarifications or remove it. We'll document changes to maintain transparency.\n",
    "\n",
    " - [X] **E.3 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
    "\n",
    "> Since this is a published report and not a live system/model, rollback for us would mean removing or revising figures and tables and documenting changes in a log. \n",
    "\n",
    " - [X] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
    "\n",
    "> A key use could be misusing demographic breakdowns to stereotype and create exclusionary arguments. We'll mitigate this by avoiding normative claims, providing contextual limitations, and adding a statement to only use it for appropriate use. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Expectations "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Individual members are expected to complete their assigned parts of a given task on time.\n",
    "* Members are expected to communicate to each other through text, Zoom, and in-person meetings every week.\n",
    "* Members are expected to address conflicts calmly and focus on solutions beneficial to the team.\n",
    "* Members are expected to support each other, share resources, and ask for help when needed to ensure the team succeeds. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Timeline Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---| \n",
    "| 2/1  | 4:00 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 2/3  |  8:00 PM |  Read 3–5 peer-reviewed articles related to International Student Admissions; summarize key findings in shared doc (at least 5 bullet points per person). | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/4  | 7:00 PM | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14 | 8:00 PM | Being clear and think about what's the problem of the project proposal. Plan a workflow to refine everyones' own distibuted part. | Discuss how to refine our project proposal as a whole. Help each other (provide advice) to figure out some existing problems|\n",
    "| 2/18  | 8:30 PM  | Work session：Data Integration: Merge multiple datasets; Initial Cleaning:Quantify missingness (% per column); decide between drop vs. imputation (mean/median/mode); document decision in notebook markdown. | Wrangling Review: Verify data integrity after merging; EDA Deep Dive: Analyze distributions of key variables & identify outliers; Refine Analysis Plan: Select specific statistical tests/models based on EDA trends.   |\n",
    "| 2/22 | 8:00 PM | Advanced EDA: Generate correlation matrix & scatterplot matrices; Initial Hypothesis Testing.| Feature Selection: Discuss which variables to keep/drop based on correlation; Address Data Bias: Identify any systematic bias in the dataset (Ethics).|\n",
    "| 2/28 | 8:00 PM | Feature Engineering: One-hot encoding for categorical data; Scaling/Normalization of numerical data | Define Analysis Pipeline: Finalize the choice of ML models (e.g., Regression vs. Classification); Assign members to code specific models. |\n",
    "| 3/4  | 8:00 PM | Execute Baseline Models; Generate performance metrics (e.g., Accuracy, MSE, R-squared). | Model Evaluation: Compare performance across different models; Identify potential underfitting or overfitting; Complete project check-in. |\n",
    "| 3/11  | 8:00 PM (Tentative) | Hyperparameter Tuning: Refine models for better performance; Finalize Visualizations (Final polished plots). | Result Interpretation: Explain the \"Why\" behind the results; Finalize Ethics & Privacy discussion based on final results; Relate findings back to original hypothesis; evaluate whether results support or reject it (statistical significance threshold α=0.05). Review project limitations. |\n",
    "| 3/12  | 8:00 PM (Tentative) | Draft Results, Conclusion, and Discussion sections; Clean up Jupyter Notebook code and comments. | Full Project Review: Peer-edit the narrative for clarity and flow; Ensure reproducibility (Run the notebook from top to bottom). |\n",
    "| 3/18  | Before 11:59 PM  | Final proofreading; Ensure all citations and references are formatted correctly. | Final Submission: Turn in Final Project & complete Group Project Surveys. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version Control & Workflow\n",
    "\n",
    "We will use GitHub for version control. Each team member will work on separate feature branches and submit pull requests before merging into the main branch. All major analytical decisions (e.g., data cleaning strategies, model selection, evaluation metrics) will be documented in markdown cells within the notebook. We will ensure full reproducibility by running the notebook from top to bottom before submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b860a9f5fc21240e9d88c0ee13691518c3ce67be252e54a03b9b5b11bd3c7a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
